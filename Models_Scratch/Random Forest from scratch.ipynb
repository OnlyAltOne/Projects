{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <div style=\"text-align: right\"> Random Forest from scratch. </div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> Geoff Counihan - Oct 6, 2017 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "---\n",
    "\n",
    "Inhereted my decision tree class to create a random forest classifier. There are a few modifications.\n",
    "\n",
    "    1. Sample with replacement\n",
    "    2. Create, predict, and average multiple tree predictions\n",
    "    3. Modify split function to spit off n_feat random features\n",
    "    \n",
    "__Additions__: Entropy, Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from scratch import decision_tree, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xy = pd.read_csv('./sonar.all-data.csv',header=None)\n",
    "Xy[60] = Xy[60].map({'R':0,'M':1})\n",
    "X = np.array(Xy.iloc[:,:-1])\n",
    "y = np.array(Xy.iloc[:,-1])\n",
    "Xy = np.array(Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulations\n",
    "\n",
    "Random Forests are powerful because they ensemble a large number of weak learners. For each tree to be different from another two manipulations are performed\n",
    "\n",
    "---\n",
    "\n",
    "__Sample with replacement__ - create a ficticous dataset sampled with replacement from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samp(Xy,ratio):\n",
    "    n = int(np.round(len(Xy) * ratio))\n",
    "    idx = np.random.randint(Xy.shape[0],size=n)\n",
    "    return Xy[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Best split from subset of features__ - the best split for trees within a random forest is actually made based on a subset of features n_feats. This encourages wildly different trees structures within the forest. In this case I've hardcoded the number of features to be the sqrt(total features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create class.\n",
    "\n",
    "---\n",
    "\n",
    "In this case, I've inhereted the class decision_tree from my decision tree built from scratch and modified functions as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modified Fit__ - calculates n_feats as well as creates a list of trained trees the length of num_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modified predict__ - makes the predictions from the list of num_trees, stacks them together, and then averages the score to a single output per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_forest(decision_tree):\n",
    "    def __init__(self, num_trees, max_depth=2, min_num_split=30, sample_ratio=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_num_sample = min_num_split\n",
    "        self.num_trees = num_trees\n",
    "        self.ratio = sample_ratio\n",
    "        \n",
    "    def build_tree(self, Xy):\n",
    "        '''Recursively build tree, unclear if this is the correct way\n",
    "        \n",
    "        '''\n",
    "        self.root = self.best_split(Xy)\n",
    "        #print(self.root)\n",
    "        self.split_branch(self.root, 1) # i don't understand how this is working, pointed to node?\n",
    "        #print(self.root)\n",
    "        return self.root\n",
    "    \n",
    "    def best_split(self, Xy):\n",
    "        classes = np.unique(Xy[:,-1])\n",
    "        best_feat = 999\n",
    "        best_val = 999\n",
    "        best_score = 999\n",
    "        best_groups = None\n",
    "        n_feats = np.random.choice(Xy.shape[1]-1, self.n_feat, replace=False)\n",
    "        #print(n_feats)\n",
    "        for feat in n_feats:\n",
    "            for i in Xy:\n",
    "                groups = self.split(feat, i[feat], Xy)\n",
    "                #print(groups)\n",
    "                gini = self.gini_score(groups, classes)\n",
    "                #print('feat {}, valued < {}, scored {}'.format(feat,i[feat], gini))\n",
    "                if gini < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = gini\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def samp(self, Xy, ratio=1):\n",
    "        n = int(np.round(len(Xy) * ratio))\n",
    "        idx = np.random.randint(Xy.shape[0],size=n)\n",
    "        return Xy[idx,:]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''Save training data.\n",
    "        \n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Xy = np.column_stack((X, y))\n",
    "\n",
    "        self.n_feat = int(np.sqrt(X.shape[1]))\n",
    "        \n",
    "        self.trees = [self.build_tree(self.samp(self.Xy)) for i in range(self.num_trees)]\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        self.y_preds = np.array([]).reshape(0,X_test.shape[0])\n",
    "        for root in self.trees:\n",
    "            y_pred = np.array([])\n",
    "            for i in X_test:\n",
    "                y_pred = np.append(y_pred,self.predict_sample(root,i))\n",
    "            #print(y_pred.shape)\n",
    "            self.y_preds = np.vstack((self.y_preds,y_pred))\n",
    "        self.avg_preds = np.rint(self.y_preds.mean(axis=0))\n",
    "        return self.avg_preds\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xy = pd.read_csv('./sonar.all-data.csv',header=None)\n",
    "Xy[60] = Xy[60].map({'R':0,'M':1})\n",
    "X = np.array(Xy.iloc[:,:-1])\n",
    "y = np.array(Xy.iloc[:,-1])\n",
    "Xy = np.array(Xy)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = random_forest(num_trees=3)\n",
    "rf.fit(X,y)\n",
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feat': 46,\n",
       "  'left': {'feat': 8, 'left': 0.0, 'right': 1.0, 'val': 0.12520000000000001},\n",
       "  'right': {'feat': 13, 'left': 1.0, 'right': 0.0, 'val': 0.43980000000000002},\n",
       "  'val': 0.12520000000000001},\n",
       " {'feat': 9,\n",
       "  'left': {'feat': 46, 'left': 0.0, 'right': 1.0, 'val': 0.16339999999999999},\n",
       "  'right': {'feat': 32, 'left': 0.0, 'right': 1.0, 'val': 0.19839999999999999},\n",
       "  'val': 0.16309999999999999},\n",
       " {'feat': 8,\n",
       "  'left': {'feat': 14, 'left': 0.0, 'right': 1.0, 'val': 0.32319999999999999},\n",
       "  'right': {'feat': 15, 'left': 1.0, 'right': 0.0, 'val': 0.65920000000000001},\n",
       "  'val': 0.1037}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens = RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=30)\n",
    "ens.fit(X_train,y_train)\n",
    "sk_rf_pred = ens.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=2,min_samples_split=30)\n",
    "clf.fit(X_train,y_train)\n",
    "sk_dt_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = decision_tree(max_depth=3,min_num_split=30)\n",
    "dt.fit(X_train,y_train)\n",
    "dt_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = random_forest(max_depth=3,num_trees=50,min_num_split=30)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy differences\n",
    "\n",
    "---\n",
    "\n",
    "I'm unclear how sklearn differs. Will need to look deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(dt_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(rf_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(sk_dt_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(sk_rf_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0, 1, 1, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 0.0, 0, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 0.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 0.0, 0, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 0.0, 0, 0, 1),\n",
       " (1.0, 1.0, 0, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 0.0, 0, 0, 1),\n",
       " (1.0, 0.0, 0, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 1),\n",
       " (1.0, 0.0, 0, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 0.0, 0, 1, 1),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (1.0, 1.0, 1, 0, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 1.0, 1, 0, 0),\n",
       " (1.0, 1.0, 1, 1, 0),\n",
       " (1.0, 1.0, 1, 1, 1),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 0.0, 0, 0, 0),\n",
       " (0.0, 0.0, 0, 0, 0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(rf_pred,dt_pred,sk_dt_pred,sk_rf_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
