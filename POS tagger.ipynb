{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and predicting with a part-of-speech tagging model\n",
    "\n",
    "---\n",
    "\n",
    "Tutorial followed along from: http://nlpforhackers.io/training-pos-tagger/\n",
    "\n",
    "POS tagging is the basis of nearly all NLP related tasks downstream. Therefore, learning how POS tagging works is a good first step when entering NLP. I wish I could'ev used this on my 6th grade english homework.\n",
    "\n",
    "### Labeled POS datasets\n",
    "\n",
    "To create a supervised model to tag parts-of-speech you need a labeled dataset! Luckily, NLTK, a python package, comes with one right out of the box. It is found in:\n",
    "\n",
    "    nltk.corpus.treebank.tagged_sents()\n",
    "    \n",
    "Other datasets commonly used are:\n",
    "\n",
    "    penn treebank\n",
    "    \n",
    "Interestingly, since twitter and conversational text have far more nuanced, grundgy, and slangy terms there are also datasets to train pos-tagging from twitter:\n",
    "\n",
    "    http://www.cs.cmu.edu/~ark/TweetNLP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"/Volumes/Secondary/\")\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import pickle\n",
    "#from sklearn import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 1161192\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.brown.tagged_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature set to be used to predict word's part of speech\n",
    "\n",
    "---\n",
    "\n",
    "Intuition and feature choice learned here: https://www.youtube.com/watch?v=LivXkL2DO_w\n",
    "\n",
    "Inclusion of features comes from our natural domain knowledge of the english language. We intuitively know many rules that we would want to include when predicting part of speech. Some are below:\n",
    "    - Capitalization - usually a proper noun\n",
    "    - Prefix - \n",
    "    - Suffix - 'ly' refers to adverbs\n",
    "    - Numeric -\n",
    "    - Position in sentence - First or Last word   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for the word 'went':  {'word': 'went', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'w', 'prefix-2': 'we', 'prefix-3': 'wen', 'suffix-1': 't', 'suffix-2': 'nt', 'suffix-3': 'ent', 'prev_word': 'Geoff', 'next_word': 'to', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}\n"
     ]
    }
   ],
   "source": [
    "sent = 'Geoff went to the library today'\n",
    "token_sent = word_tokenize(sent)\n",
    "print(\"Example for the word 'went': \",features(sentence=token_sent,index=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the tagged corpus into train/test\n",
    "\n",
    "---\n",
    "\n",
    "First we must seperate the tags from the corpus words. The tags are the 'y'. To create our 'X' we first will take the words, then run them through our featurizing function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut = int(.7 * len(tagged_sentences))\n",
    "training_sentences = tagged_sentences[:cut]\n",
    "testing_sentences = tagged_sentences[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739\n",
      "1175\n"
     ]
    }
   ],
   "source": [
    "print(len(training_sentences))\n",
    "print(len(testing_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence,t='word'):\n",
    "    if t == 'word':\n",
    "        return [w for w,t in tagged_sentence]\n",
    "    elif t == 'tag':\n",
    "        return [t for w,t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_tagged_Xy(tagged_sentences):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for tagged_sentence in tagged_sentences:\n",
    "        for i, word_tag in enumerate(tagged_sentence):\n",
    "            X.append(features(untag(tagged_sentence),i))\n",
    "            word, tag = word_tag\n",
    "            y.append(tag)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: tag and word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-68e72cdac826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "print(y[i])\n",
    "print(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = transform_tagged_Xy(training_sentences)\n",
    "X_test, y_test = transform_tagged_Xy(testing_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DictVectorizer\n",
    "\n",
    "---\n",
    "\n",
    "The 'X' features are still in a dictionary format, so we can use sklearn.DictVectorizer to convert the raw feature information in 'X' into a numpy array of one-hot encodded data. For more info see: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/dict_vectorizer.py\n",
    "\n",
    "It is similar to the CountVectorizer, in the sense that the more data it is 'fit' with the more columns will be associated with each sample. \n",
    "\n",
    "In addition, any unseen data at transform will be mapped to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'capitals_inside': False,\n",
       "  'has_hyphen': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_first': True,\n",
       "  'is_last': False,\n",
       "  'is_numeric': False,\n",
       "  'next_word': 'Vinken',\n",
       "  'prefix-1': 'P',\n",
       "  'prefix-2': 'Pi',\n",
       "  'prefix-3': 'Pie',\n",
       "  'prev_word': '',\n",
       "  'suffix-1': 'e',\n",
       "  'suffix-2': 're',\n",
       "  'suffix-3': 'rre',\n",
       "  'word': 'Pierre'},\n",
       " {'capitals_inside': False,\n",
       "  'has_hyphen': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'is_numeric': False,\n",
       "  'next_word': ',',\n",
       "  'prefix-1': 'V',\n",
       "  'prefix-2': 'Vi',\n",
       "  'prefix-3': 'Vin',\n",
       "  'prev_word': 'Pierre',\n",
       "  'suffix-1': 'n',\n",
       "  'suffix-2': 'en',\n",
       "  'suffix-3': 'ken',\n",
       "  'word': 'Vinken'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting only sample 1, the length of resulting vector sample 1:  17\n",
      "fitting only sample 1-3, the length of resulting vector sample 1:  162\n"
     ]
    }
   ],
   "source": [
    "#fitting only sample 1, the length of resulting vector sample 1 is len 17\n",
    "print('fitting only sample 1, the length of resulting vector sample 1: ',len(dv.fit_transform(X_train[:1])[0]))\n",
    "#fitting samples 1-3, the length of resulting vector sample 1 is len 35\n",
    "print('fitting only sample 1-3, the length of resulting vector sample 1: ',len(dv.fit_transform(X_train[:20])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.fit_transform(X_train[:20])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now time to train the model\n",
    "\n",
    "---\n",
    "\n",
    "Using a pipeline, first DictVectorize the features, then train a classifier. I chose randomforrest because I have had good results with it in the past. \n",
    "\n",
    "The original author in a sense, stunted the growth of the model by only training on the first 10k samples. Once running it a couple times its clear why. Due to the DictVectorizer the more samples added and unique prefix and suffixes balloon the dimensionality of 'X' exponentially. On my computer training 10k is ~1.5mins where as training 20k is ~5.5mins.\n",
    "\n",
    "The result is ~93% accuracy! Though this seems good, it might be misrepresenting its performance since F1 is usually used for NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "#    ('classifier', DecisionTreeClassifier(criterion='entropy')),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100,criterion='entropy')),\n",
    "])\n",
    "\n",
    "#clf.fit(X[:20000], y[:20000])   # Use only the first 10K samples if you're running it multiple times. It takes a fair bit :)\n",
    "\n",
    "clf.fit(X_train[:20000], y_train[:20000])\n",
    " \n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In addition, this is a good time to save the trained model so it can be used int he future without retraining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"20k_pos_tagger.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have a model trained, lets wrap it up to predict future parts of speech\n",
    "\n",
    "---\n",
    "\n",
    "I chose to add the word_tokenizer into the function and allow on/off functionality with a flag after I ran into an issue below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_pos_tags(sent,token_sent_on=False):\n",
    "    global clf\n",
    "    \n",
    "    if clf:\n",
    "        pass\n",
    "    else:\n",
    "        clf = pickle.load(open(\"20k_pos_tagger.p\", \"rb\"))\n",
    "    \n",
    "    '''Takes a sentence, and predicts the part of speech tag for each word.\n",
    "    \n",
    "    '''\n",
    "    if token_sent_on == True:\n",
    "        token_sent = word_tokenize(sent)\n",
    "    else:\n",
    "        token_sent = sent\n",
    "    \n",
    "    sentence_features = []\n",
    "    sentence_tags = []\n",
    "    \n",
    "    for i, word in enumerate(token_sent):\n",
    "        sentence_features.append(features(token_sent,index=i))\n",
    "        sentence_tags.append(clf.predict(features(token_sent,index=i))[0])\n",
    "    \n",
    "    return list(zip(token_sent,sentence_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = pickle.load(open(\"20k_pos_tagger.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Geoff', 'NNP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('library', 'NN'),\n",
       " ('today', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Geoff went to the library today.'\n",
    "predict_pos_tags(sentence,token_sent_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Geoff', 'NNP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('library', 'NN'),\n",
       " ('today', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sent = ['Geoff','went','to','the','library','today','.']\n",
    "predict_pos_tags(token_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK has an out-of-the-box POS tagger, lets compare performance\n",
    "\n",
    "---\n",
    "\n",
    "Even on the simple example sentance the NLTK parser and ours has a discripency! This is great! Lets see how well they perform on the test corpus. Since our POS tagger was trained on it we can only use the test data.\n",
    "\n",
    "The following blocks of code are only to format the train/test into a way the NLTK_POS can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Geoff', 'NNP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('library', 'JJ'),\n",
       " ('today', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(token_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_tagged_Xy(tagged_sentences):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for tagged_sentence in tagged_sentences:\n",
    "        X.append(untag(tagged_sentence))\n",
    "        for i, word_tag in enumerate(tagged_sentence):\n",
    "            word, tag = word_tag\n",
    "            y.append(tag)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = remove_tagged_Xy(testing_sentences)\n",
    "\n",
    "y_pred = nltk.pos_tag_sents(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_word = [word for pred in y_pred for word, pos in pred]\n",
    "y_pred = [pos for pred in y_pred for word, pos in pred]\n",
    "\n",
    "zipped_y_pred = list(zip(y_word,y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have a list of word/pos_pred/pos_truth, we can make a scorer\n",
    "\n",
    "---\n",
    "\n",
    "Keep a count of which the model predicted correctly and which it didn't. Also keep track of which words it incorrectly predicted - perhaps the NLTK model will predict differently than ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_pred(zipped_y_pred):\n",
    "    '''Score accuracy of predictions of NLTK and custom POS tagger.\n",
    "    '''\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    y_error = []\n",
    "    \n",
    "    for word, y_pred, y_test in zipped_y_pred:\n",
    "        if y_pred == y_test:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            y_error.append((word,y_pred,y_test))\n",
    "            \n",
    "    print('number correct: ', correct)\n",
    "    print('number incorrect: ', incorrect)\n",
    "\n",
    "    accuracy = correct/(correct+incorrect)\n",
    "    \n",
    "    return accuracy, y_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number correct:  26552\n",
      "number incorrect:  3067\n"
     ]
    }
   ],
   "source": [
    "nltk_score, nltk_errors = score_pred(zipped_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create same format for custom POS parser\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC', 'DT', 'NN', 'MD', 'RB']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pos for word, pos in predict_pos_tags(X_test[0])][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_word = []\n",
    "y_pred = []\n",
    "\n",
    "for sent in X_test:\n",
    "    y_word.append(untag(predict_pos_tags(sent)))\n",
    "    y_pred.append(untag(predict_pos_tags(sent),t='tag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_flat = []\n",
    "y_word_flat = []\n",
    "for word, pred in zip(y_word,y_pred):\n",
    "    for pos in pred:\n",
    "        y_pred_flat.append(pos)\n",
    "    for w in word:\n",
    "        y_word_flat.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_zipped_y_pred = list(zip(y_word_flat,y_pred_flat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number correct:  27517\n",
      "number incorrect:  2102\n"
     ]
    }
   ],
   "source": [
    "custom_score, custom_errors = score_pred(custom_zipped_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the errors to see where each model is going awry\n",
    "\n",
    "---\n",
    "\n",
    "NLTK model errors:\n",
    "\n",
    "    many *'s in the errors, these don't look like real words\n",
    "    lots of 0's too\n",
    "    hyphenated words\n",
    "    proper nouns\n",
    "    not many common words incorrectly tagged\n",
    "    \n",
    "Custom model:\n",
    "\n",
    "    some proper nouns\n",
    "    errors look like more common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "custom_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = '*RNR*-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match = re.search('\\*',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zero_count = 0\n",
    "astrict_count = 0\n",
    "nltk_no_astrict_errors = []\n",
    "\n",
    "for tup in nltk_errors:\n",
    "    match1 = re.search('\\*',tup[0])\n",
    "    match2 = re.search('0',tup[0])\n",
    "    if match1:\n",
    "        astrict_count += 1\n",
    "    elif match2:\n",
    "        zero_count += 1\n",
    "    else:\n",
    "        nltk_no_astrict_errors.append(tup)\n",
    "        \n",
    "print('astrict count: ',astrict_count)\n",
    "print('zero count: ', zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk_no_astrict_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculating score ommiting astricts and zero errors from the NLTK model\n",
    "\n",
    "---\n",
    "\n",
    "Manually taking the print out of our score function:\n",
    "\n",
    "    number correct:  26552\n",
    "    number incorrect:  3067\n",
    "    \n",
    "And subracting the astrict errors:\n",
    "\n",
    "    astrict count:  1599\n",
    "    zero count:  344\n",
    "    \n",
    "This is much better than our model's performance, but we'll see if we can add extra features to ours to make it more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 26552\n",
    "incorrect = 3067\n",
    "\n",
    "incorrect_astrict = 1599\n",
    "incorrect_zero = 344\n",
    "incorrect = incorrect - incorrect_astrict - incorrect_zero\n",
    "\n",
    "total = correct + incorrect\n",
    "\n",
    "correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "---\n",
    "\n",
    "All in all, our model was only trained on 20k samples of the total ~70k and performs only 3% worse in terms of accuracy than the out-of-the-box NLTK POS tagger. I'm pretty happy with this. All credit for the feature rules given to Bogdani from the tutorial above.\n",
    "\n",
    "I'd like to calculate precision and recall to get an F1 score in a later exercise - since I've read this is what NLP models are commonly based on. Perhaps theres a better way than coding up counters myself though. I'll read into it before diving in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
