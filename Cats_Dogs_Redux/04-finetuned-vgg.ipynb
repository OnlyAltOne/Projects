{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cat Redux\n",
    "\n",
    "---\n",
    "\n",
    "Notebook to finetune different architectures. Using full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5005 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1060 6GB (0000:04:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import he_normal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plan:\n",
    "\n",
    "1. create decent size sample to work through ideas quickly\n",
    "2. once a good approach is found automate it for full dataset\n",
    "2. extra! create an ensemble with the sample data frist\n",
    "3. __create a finetuned model of the best proto on full data__\n",
    "3. submit to kaggle 3x times tonight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frozen_vggbn():\n",
    "    vggbn = Vgg16BN()\n",
    "    vggbn = vggbn.model\n",
    "    for layer in vggbn.layers:\n",
    "        layer.trainable = False\n",
    "    return vggbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def half_frozen_vggbn(depth):\n",
    "    '''Transfer learning from vggbn to a frozen model based on given depth.\n",
    "    '''\n",
    "    vggbn = Vgg16BN()\n",
    "    vggbn = vggbn.model\n",
    "    vggbn.pop()\n",
    "    for layer in vggbn.layers[:depth]:\n",
    "        #print('Freezing {}'.format(layer.name))\n",
    "        layer.trainable = False\n",
    "    for layer in vggbn.layers[depth:]:\n",
    "        if 'dense' in layer.name:\n",
    "            #print('Changing {} to he_normal initilizer'.format(layer.name))\n",
    "            layer.kernel_initializer = he_normal()\n",
    "    return vggbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Save results get data from appropriate places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_train_path = '../../dogscats/lrg_sample/train/'\n",
    "sample_val_path = '../../dogscats/lrg_sample/valid/'\n",
    "\n",
    "train_path = '../../dogscats/train/'\n",
    "val_path = '../../dogscats/valid/'\n",
    "\n",
    "sample_results_path = '../../dogscats/lrg_sample/results/'\n",
    "sample_model_path = '../../dogscats/lrg_sample/models/'\n",
    "\n",
    "model_path = '../../dogscats/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Set up data batches. Used both for prototyping but found that augmented is always results in better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_gen = image.ImageDataGenerator(\n",
    "    channel_shift_range=10,\n",
    "    zoom_range=0.05,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32 #32 - kept running out of mem on proto6\n",
    "\n",
    "train_batches = get_batches(train_path,batch_size=batch_size)\n",
    "aug_train_batches = aug_gen.flow_from_directory(directory=train_path,batch_size=batch_size,shuffle=True,target_size=(224,224))\n",
    "val_batches = get_batches(val_path,batch_size=batch_size*2)\n",
    "\n",
    "train_steps = train_batches.samples//train_batches.batch_size\n",
    "aug_train_steps = aug_train_batches.samples//aug_train_batches.batch_size\n",
    "val_steps = val_batches.samples//val_batches.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Ensemble time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_proto8():\n",
    "    vggbn = half_frozen_vggbn(-14)\n",
    "    for i in range(5):\n",
    "        vggbn.pop()\n",
    "    vggbn.add(BatchNormalization())\n",
    "    vggbn.add(Dropout(.6))\n",
    "    vggbn.add(Dense(2,activation='softmax',kernel_initializer='he_normal'))\n",
    "    vggbn.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return vggbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_proto4():\n",
    "    vggbn = frozen_vggbn()\n",
    "    vggbn.pop()\n",
    "    vggbn.add(Dense(2,activation='softmax',kernel_initializer='he_normal'))\n",
    "    vggbn.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return vggbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_func,i,epochs=10):\n",
    "    model = model_func()\n",
    "    cb = [ModelCheckpoint(model_path+'lone_{}_{}'.format(model_name,i), monitor='val_loss', save_best_only=True, save_weights_only=False)]\n",
    "    model.fit_generator(aug_train_batches, aug_train_steps, epochs=epochs, callbacks=cb,\n",
    "                    validation_data=val_batches, validation_steps=val_steps)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Finetuning proto8 model from above with full data and modifying the learning rate. In addition, it seems to be overfitting quite highly now, so I'm going tp up the dropout from .5 to .6\n",
    "\n",
    "I accidentally overwrote the ens_prod8_2 data with the single model. Thast why I'm loading it in as opposed to a lone_prod8_2\n",
    "\n",
    "    LD score of .08891 (dropout .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'prod8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "718/718 [==============================] - 351s - loss: 0.1279 - acc: 0.9543 - val_loss: 0.1830 - val_acc: 0.9466\n",
      "Epoch 2/10\n",
      "718/718 [==============================] - 339s - loss: 0.0845 - acc: 0.9694 - val_loss: 0.0599 - val_acc: 0.9783\n",
      "Epoch 3/10\n",
      "718/718 [==============================] - 339s - loss: 0.0598 - acc: 0.9785 - val_loss: 0.0485 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "718/718 [==============================] - 348s - loss: 0.0505 - acc: 0.9832 - val_loss: 0.0349 - val_acc: 0.9861\n",
      "Epoch 5/10\n",
      "718/718 [==============================] - 339s - loss: 0.0383 - acc: 0.9856 - val_loss: 0.0365 - val_acc: 0.9902\n",
      "Epoch 6/10\n",
      "718/718 [==============================] - 340s - loss: 0.0348 - acc: 0.9883 - val_loss: 0.0388 - val_acc: 0.9902\n",
      "Epoch 7/10\n",
      "718/718 [==============================] - 337s - loss: 0.0428 - acc: 0.9841 - val_loss: 0.0869 - val_acc: 0.9814\n",
      "Epoch 8/10\n",
      "718/718 [==============================] - 352s - loss: 0.0311 - acc: 0.9887 - val_loss: 0.0308 - val_acc: 0.9907\n",
      "Epoch 9/10\n",
      "718/718 [==============================] - 496s - loss: 0.0239 - acc: 0.9919 - val_loss: 0.0359 - val_acc: 0.9876\n",
      "Epoch 10/10\n",
      "718/718 [==============================] - 354s - loss: 0.0246 - acc: 0.9917 - val_loss: 0.0369 - val_acc: 0.9886\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "model_num = 2\n",
    "model = train_model(get_proto8,model_num,epochs=10)\n",
    "\n",
    "model.load_weights(model_path+'ens_{}_{}'.format(model_name,model_num))\n",
    "\n",
    "test_batches = get_batches('../../dogscats/test/',batch_size=batch_size,shuffle=False)\n",
    "test_steps = test_batches.n//test_batches.batch_size+1\n",
    "y_pred = model.predict_generator(test_batches,steps=test_steps)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(model_path+'lone_{}_{}_pred'.format(model_name,model_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "718/718 [==============================] - 362s - loss: 0.0267 - acc: 0.9907 - val_loss: 0.0377 - val_acc: 0.9886\n",
      "Epoch 2/10\n",
      "718/718 [==============================] - 348s - loss: 0.0348 - acc: 0.9879 - val_loss: 0.0462 - val_acc: 0.9871\n",
      "Epoch 3/10\n",
      "718/718 [==============================] - 348s - loss: 0.0267 - acc: 0.9906 - val_loss: 0.0360 - val_acc: 0.9897\n",
      "Epoch 4/10\n",
      "718/718 [==============================] - 365s - loss: 0.0162 - acc: 0.9952 - val_loss: 0.0398 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "718/718 [==============================] - 348s - loss: 0.0164 - acc: 0.9942 - val_loss: 0.0512 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      "718/718 [==============================] - 349s - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0661 - val_acc: 0.9855\n",
      "Epoch 7/10\n",
      "718/718 [==============================] - 353s - loss: 0.0142 - acc: 0.9950 - val_loss: 0.0478 - val_acc: 0.9871\n",
      "Epoch 8/10\n",
      "718/718 [==============================] - 355s - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "Epoch 9/10\n",
      "718/718 [==============================] - 351s - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0555 - val_acc: 0.9871\n",
      "Epoch 10/10\n",
      "718/718 [==============================] - 355s - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0715 - val_acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8820edae80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = [ModelCheckpoint(model_path+'ens_{}_{}'.format(model_name,2), monitor='val_loss', save_best_only=True, save_weights_only=False)]\n",
    "model.fit_generator(aug_train_batches, aug_train_steps, epochs=10, callbacks=cb,\n",
    "                    validation_data=val_batches, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Bumped the dropout to .6 and retuned the model another 5 epochs\n",
    "\n",
    "    LD score of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "718/718 [==============================] - 353s - loss: 0.1216 - acc: 0.9569 - val_loss: 0.0623 - val_acc: 0.9798\n",
      "Epoch 2/5\n",
      "718/718 [==============================] - 347s - loss: 0.0695 - acc: 0.9738 - val_loss: 0.0333 - val_acc: 0.9886\n",
      "Epoch 3/5\n",
      "718/718 [==============================] - 335s - loss: 0.0573 - acc: 0.9803 - val_loss: 0.0807 - val_acc: 0.9819\n",
      "Epoch 4/5\n",
      "717/718 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9822"
     ]
    }
   ],
   "source": [
    "model_num = 2\n",
    "model_name = 'prod8'\n",
    "model = train_model(get_proto8,model_num,epochs=5)\n",
    "\n",
    "model.load_weights(model_path+'ens_{}_{}'.format(model_name,model_num))\n",
    "\n",
    "test_batches = get_batches('../../dogscats/test/',batch_size=batch_size,shuffle=False)\n",
    "test_steps = test_batches.n//test_batches.batch_size+1\n",
    "y_pred = model.predict_generator(test_batches,steps=test_steps)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(model_path+'lone_{}_{}_pred'.format(model_name,model_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Went rogue at night and wanted to run a 50e of the proto8, surprisingly did poorly in the submission. \n",
    "\n",
    "    LD score of .09176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "718/718 [==============================] - 360s - loss: 0.1513 - acc: 0.9442 - val_loss: 0.0972 - val_acc: 0.9688\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 334s - loss: 0.1116 - acc: 0.9580 - val_loss: 0.1723 - val_acc: 0.9576\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 333s - loss: 0.0932 - acc: 0.9660 - val_loss: 0.3273 - val_acc: 0.9127\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 333s - loss: 0.0994 - acc: 0.9636 - val_loss: 0.1061 - val_acc: 0.9597\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 341s - loss: 0.0716 - acc: 0.9744 - val_loss: 0.0565 - val_acc: 0.9778\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 333s - loss: 0.0642 - acc: 0.9776 - val_loss: 0.0609 - val_acc: 0.9824\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 334s - loss: 0.0516 - acc: 0.9823 - val_loss: 0.1017 - val_acc: 0.9690\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 341s - loss: 0.0482 - acc: 0.9830 - val_loss: 0.0422 - val_acc: 0.9861\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 353s - loss: 0.0458 - acc: 0.9849 - val_loss: 0.0262 - val_acc: 0.9923\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 344s - loss: 0.0368 - acc: 0.9876 - val_loss: 0.0453 - val_acc: 0.9855\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 345s - loss: 0.0373 - acc: 0.9879 - val_loss: 0.0333 - val_acc: 0.9866\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 331s - loss: 0.0327 - acc: 0.9889 - val_loss: 0.0910 - val_acc: 0.9814\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 331s - loss: 0.0245 - acc: 0.9916 - val_loss: 0.1267 - val_acc: 0.9804\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - 331s - loss: 0.0317 - acc: 0.9894 - val_loss: 0.0638 - val_acc: 0.9845\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 331s - loss: 0.0292 - acc: 0.9909 - val_loss: 0.0386 - val_acc: 0.9897\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 331s - loss: 0.0363 - acc: 0.9881 - val_loss: 0.0525 - val_acc: 0.9830\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 332s - loss: 0.0233 - acc: 0.9927 - val_loss: 0.0476 - val_acc: 0.9876\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 332s - loss: 0.0264 - acc: 0.9928 - val_loss: 0.0539 - val_acc: 0.9876\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 331s - loss: 0.0217 - acc: 0.9931 - val_loss: 0.0662 - val_acc: 0.9897\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 331s - loss: 0.0166 - acc: 0.9946 - val_loss: 0.1438 - val_acc: 0.9726\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 331s - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0593 - val_acc: 0.9840\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 331s - loss: 0.0172 - acc: 0.9946 - val_loss: 0.0640 - val_acc: 0.9871\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 331s - loss: 0.0172 - acc: 0.9952 - val_loss: 0.1107 - val_acc: 0.9793\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 331s - loss: 0.0176 - acc: 0.9954 - val_loss: 0.0801 - val_acc: 0.9861\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 331s - loss: 0.0169 - acc: 0.9953 - val_loss: 0.2003 - val_acc: 0.9804\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 331s - loss: 0.0144 - acc: 0.9956 - val_loss: 0.1088 - val_acc: 0.9757\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 331s - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0770 - val_acc: 0.9850\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 331s - loss: 0.0144 - acc: 0.9962 - val_loss: 0.1124 - val_acc: 0.9793\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 331s - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0571 - val_acc: 0.9902\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 331s - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0550 - val_acc: 0.9876\n",
      "Epoch 31/50\n",
      "718/718 [==============================] - 331s - loss: 0.0108 - acc: 0.9970 - val_loss: 0.1071 - val_acc: 0.9840\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 331s - loss: 0.0156 - acc: 0.9961 - val_loss: 0.0563 - val_acc: 0.9902\n",
      "Epoch 33/50\n",
      "718/718 [==============================] - 332s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.1048 - val_acc: 0.9849\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 331s - loss: 0.0122 - acc: 0.9964 - val_loss: 0.0678 - val_acc: 0.9876\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 332s - loss: 0.0118 - acc: 0.9969 - val_loss: 0.1491 - val_acc: 0.9845\n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 331s - loss: 0.0135 - acc: 0.9963 - val_loss: 0.0994 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "718/718 [==============================] - 331s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0878 - val_acc: 0.9855\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 331s - loss: 0.0134 - acc: 0.9964 - val_loss: 0.1159 - val_acc: 0.9814\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 332s - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0878 - val_acc: 0.9881\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 331s - loss: 0.0116 - acc: 0.9968 - val_loss: 0.1307 - val_acc: 0.9819\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 331s - loss: 0.0092 - acc: 0.9975 - val_loss: 0.1693 - val_acc: 0.9788\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 331s - loss: 0.0123 - acc: 0.9972 - val_loss: 0.1166 - val_acc: 0.9892\n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 331s - loss: 0.0097 - acc: 0.9976 - val_loss: 0.1098 - val_acc: 0.9819\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 331s - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0623 - val_acc: 0.9897\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 331s - loss: 0.0096 - acc: 0.9974 - val_loss: 0.1414 - val_acc: 0.9861\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 332s - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0610 - val_acc: 0.9902\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 332s - loss: 0.0097 - acc: 0.9979 - val_loss: 0.0715 - val_acc: 0.9871\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 331s - loss: 0.0086 - acc: 0.9978 - val_loss: 0.0836 - val_acc: 0.9866\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 331s - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1973 - val_acc: 0.9762\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 331s - loss: 0.0086 - acc: 0.9980 - val_loss: 0.1429 - val_acc: 0.9809\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "model_num = 1\n",
    "model = train_model(get_proto8,model_num,epochs=50)\n",
    "\n",
    "hist = model.load_weights(model_path+'ens_{}_{}'.format(model_name,model_num))\n",
    "\n",
    "test_batches = get_batches('../../dogscats/test/',batch_size=batch_size,shuffle=False)\n",
    "test_steps = test_batches.n//test_batches.batch_size+1\n",
    "y_pred = model.predict_generator(test_batches,steps=test_steps)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(model_path+'lone_{}_{}_pred'.format(model_name,model_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Create final pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'prod8'\n",
    "model_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "model = get_proto8()\n",
    "model.load_weights(model_path+'lone_{}_{}'.format(model_name,model_num))\n",
    "\n",
    "test_batches = get_batches('../../dogscats/test/',batch_size=batch_size,shuffle=False)\n",
    "test_steps = test_batches.n//test_batches.batch_size+1\n",
    "y_pred = model.predict_generator(test_batches,steps=test_steps)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(model_path+'lone_{}_{}_pred'.format(model_name,model_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Load saved predictions of models and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens_preds = pd.DataFrame()\n",
    "for i in range(model_num):\n",
    "    df = pd.read_csv(model_path+'lone_{}_{}_pred'.format(model_name,i+1),index_col=0)\n",
    "    ens_preds = pd.concat([ens_preds,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog_preds = ens_preds.drop('0',axis=1)\n",
    "avg_preds = dog_preds.mean(axis=1)\n",
    "avg_preds = np.array(avg_preds)\n",
    "avg_preds = avg_preds.clip(min=0.05, max=0.95)\n",
    "#avg_preds = avg_preds.clip(lower=0.05,upper=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = test_batches.filenames\n",
    "full_files = [f.split('/')[1] for f in filenames]\n",
    "ids = [int(f.split('.')[0]) for f in full_files]\n",
    "formatted = np.stack([ids,avg_preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_path = '../../dogscats/submissions/'\n",
    "np.savetxt(sub_path+'lone_{}_{}_pred.csv'.format(model_name,model_num), formatted, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and submit:\n",
    "\n",
    "---\n",
    "Use this command to download file from server. Must be done from the client *not* from this notebook\n",
    "\n",
    "    scp 96.237.225.57:/home/xbno/anaconda3/courses/dogscats/submissions/submission1.csv ~/Desktop/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
